# Model Evaluation
---
## 1. Model Evaluation Overview

In `Part 2: Model Fine-Tuning`, we compared the performance of six fine-tuning approaches against the base model using `Similarity Score`. In this section, we further evaluate the fine-tuned models by comparing their performance with OpenAI's `GPT-4o`, a state-of-the-art multimodal model available on the market.

As shown in the [Model Quality Comparison](#3-model-quality-comparison) section below, the `base model` ([Idefics2](https://huggingface.co/blog/idefics2)), although unable to identify exhibits, is generally capable of describing them as general objects. `GPT-4o` typically provides highly detailed descriptions of exhibits as general objects and, in some cases, even correctly identifies well-known museum exhibits (e.g., `Wright Flyer`).  

Our `fine-tuned model` demonstrates the highest answer quality. It not only accurately identifies and describes the exhibit in great detail but also incorporates insights into its historical significance and social impact. This is achieved because the model has been trained on high-quality, domain-specific data, allowing for more precise and contextually rich responses.

## 2. Model Evaluation Process

During evaluation, we use the same dataset created in `Part 1: Synthetic Data Creation`. Specifically, we use its test split to calculate similarity scores for the `base model`, `LoRA fine-tuned model`, `Full fine-tuned model`, and `OpenAI GPT-4o` (via API).  

For the `base model`, `LoRA fine-tuned model`, and `Full fine-tuned model`, we use previously computed similarity scores without rerunning inference. These scores were obtained from the [Complete LoRA Fine-Tuning Notebook](../2_model_finetuning/2.1_lora_finetuning/run_1_a6000_48g_x1/lora_finetuning_complete.ipynb) and the [Full Fine-Tuning Notebook](../2_model_finetuning/2.4_full_finetuning/run_1_a100_80g_x1/full_finetuning.ipynb).

For `OpenAI GPT-4o`, we submit the user query along with the exhibit image to the OpenAI GPT-4o API. The generated answers returned from the API are then used to calculate similarity scores. Please note that our similarity score calculation method is based on measuring the `contextual embedding distance` between the `Ground Truth` and the `generated answer` in the `embedding vector space` of the base or fine-tuned model. Therefore, we first need to load a base model from Hugging Face before performing the similarity score calculation.  

Finally, we plot the similarity scores of the `base model`, `LoRA fine-tuned model`, `Full fine-tuned model`, and `OpenAI GPT-4o` side by side for direct comparison, using the `Ground Truth` as a reference.

## 3. Model Quality Comparison

#### Model Quality Comparison by Similarity Score

As shown in the figure below, the best possible [Similarity Score](../2_model_finetuning/model_finetuning_readme.md#similarity-score) is `0`, indicating that the model's generated answers are identical to the [Ground Truth](../2_model_finetuning/model_finetuning_readme.md#ground-truth).  

The `base model` (No Fine-Tuning) achieves a `Similarity Score` close to `0.6`, while `OpenAI GPT-4o` provides better answer quality, achieving a `Similarity Score` around `0.3`. `LoRA Fine-Tuning` significantly enhances the model's quality, reducing the `Similarity Score` to approximately `0.04`, while `Full Fine-Tuning` further improves it to around `0.03`.  

<img src="../assets/similarity_score_comparison.jpg" height="1500" alt="Similarity Score Comparison" style="border: 1px solid #ccc; padding: 5px; display: block;">

#### Model Quality Comparison by Individual Test Results

The table below demonstrates the quality of responses generated by different models. The fine-tuned models produce nuanced and informative answers, capturing intricate details about craftsmanship, history, and cultural significance. These responses offer greater depth and contextual richness compared to those from the `base model` and `OpenAI GPT-4o`.  

| **User Query** <br>(with an exhibition image and a question) | **Generated Answer from Base Model** | **Generated Answer from OpenAI GPT-4o** | **Generated Answer from LoRA Fine-Tuned Model** |
|--------------------------------------------------------------|--------------------------------------|-----------------------------------------|-------------------------------------------------|
|<img src="../assets/weathervane-teapot-1.jpg" width="1000" alt="Weathervane Teapot" style="border: 1px solid #ccc; padding: 5px; display: block;"> Can you describe this exhibit?<sup>[1]</sup>|This is a sculpture.|This exhibit is a sculpture composed of various geometric and abstract shapes. The structure includes a primary base with two triangular spikes. Several colorful elements are mounted on a horizontal rod, including spherical and rectangular forms. The right side features a white, funnel-like object with a curved yellow element attached. Above, there is a horizontal rod with blue triangular and rectangular shapes, giving it a kinetic feel similar to a mobile. The composition is modern and abstract, featuring a mix of materials and colors that create a dynamic and playful aesthetic.|This exhibit features the innovative work of Peter Shire, an artist born in Los Angeles in 1947. One of the standout pieces is the Weathervane Teapot, created in 1981, which exemplifies Shire's unique approach to ceramic art. The teapot is characterized by its playful design, incorporating colorful shapes such as squares and spheres, along with whimsical rods and hollow tubes. Shire's intention was to challenge traditional, class-based perceptions of "tea-time," making it a practice that is accessible to everyone. The teapot's unconventional construction invites viewers to engage with it, raising questions about its functionality and how to handle it. After 1985, Shire shifted his focus to furniture design, marking a significant transition in his artistic journey. This piece is part of the Smithsonian American Art Museum's collection, generously donated by Donna and John Donaldson in honor of the anniversaries of the James Renwick Alliance and the Renwick Gallery.|
|<img src="../assets/nakhla-meteorite-fragment-1.jpg" width="1000" alt="Nakhla Meteorite Fragment" style="border: 1px solid #ccc; padding: 5px; display: block;"> Can you describe this exhibit?<sup>[2]</sup>|This is a large rock that is textured and colored unevenly.|This image shows a piece of the Nakhla meteorite. The exhibit likely highlights its significance as a Martian meteorite, which fell in Egypt in 1911. The meteorite is notable for its smooth, fusion-crusted surface and the rough, lighter-colored interior, which is visible due to the cut or break. The Nakhla meteorite is famous for the story of hitting a dog and has been studied for clues about Mars's geology and potential past life.|This exhibit features the Nakhla Meteorite Fragment at the Smithsonian's National Museum of Natural History, a significant specimen among the thirty-four known meteorites that have originated from Mars. The Nakhla meteorite fell on June 28, 1911, in the Nakhla region of Alexandria, Egypt, where it was observed exploding in the atmosphere before breaking into approximately forty pieces, with a total weight of 22 pounds. Many of these fragments were found buried up to a meter deep. The Smithsonian acquired two samples shortly after the fall, and in 1962, it added a 480-gram fragment, bringing its total collection to 650 grams by the 1970s. The Nakhlites, a term referring to Martian meteorites named after Nakhla, are igneous rocks rich in augite formed from basaltic magma around 1.3 billion years ago. Research indicates that these meteorites were once hydrated and were altered by liquid water around 620 million years ago. They were ejected from Mars due to an asteroid impact about 10.75 million years ago and landed on Earth within the last 10,000 years.|
|<img src="../assets/plymouth-rock-piece-1.jpg" width="1000" alt="Plymouth Rock Piece" style="border: 1px solid #ccc; padding: 5px; display: block;"> Can you describe this exhibit?<sup>[3]</sup>|This is a rock.|This exhibit is a large, roughly hewn stone. It appears to have an uneven, textured surface with a grayish color, hinting at its possible geological origin. The shape is somewhat rectangular, with flat and angular sides, suggesting it may have been shaped or altered by human activity. This exhibit could be part of a geological, historical, or archaeological display, but specific details about its origin or significance would be needed for further context.|This exhibit features the Plymouth Rock Piece from 1620, an iconic artifact at the National Museum of American History. Traditionally regarded as the landing site of the Mayflower Pilgrims, Plymouth Rock is steeped in history. The rock's origins are somewhat mysterious, but it is believed to have been moved from its original location in the 1700s to its current spot on the shore of Plymouth Harbor. In 1880, a significant piece was discovered being used as a doorstep by the Plymouth Antiquarian Society, which was later broken into three parts. One of these pieces was donated to the Smithsonian in 1984, and museum officials accepted it in 1985. This rock fragment, measuring 22 inches by 11.5 inches, is composed of granite and has a fascinating history tied to the Pilgrims' arrival in Plymouth, Massachusetts.|
|<img src="../assets/1903-wright-flyer-8.jpg" width="1000" alt="Wright Flyer" style="border: 1px solid #ccc; padding: 5px; display: block;"> What can you tell me about this exhibit?<sup>[4]</sup>|A collection of old fashioned planes are on display in a museum.|This exhibit features the Wright Flyer, the airplane used by the Wright brothers for the first successful powered flights in 1903 at Kitty Hawk, North Carolina. It is displayed at the National Air and Space Museum in Washington, D.C. <br>The Wright Flyer was groundbreaking because it was the first powered, heavier-than-air machine to achieve controlled, sustained flight with a pilot aboard. The aircraft utilizes a biplane design with a wingspan of approximately 40 feet and was powered by a custom-built engine. The structure of the plane is made of wood and fabric, showcasing early aviation engineering.<br>This exhibit is significant as it marks the beginning of the modern aviation era and highlights the ingenuity and pioneering spirit of the Wright brothers.|The exhibit features the iconic 1903 Wright Flyer, a pioneering aircraft that marked the dawn of powered flight. Built by the Wright brothers, Wilbur and Orville, this biplane is powered by a 12-horsepower engine that operates two pusher propellers via a sprocket-and-chain system. Its unique landing gear consists of linear skids, and it is covered in natural fabric, without any paint or sealant. The Flyer made its historic first flight on December 17, 1903, in Kitty Hawk, North Carolina, with Orville at the controls for a brief 12-second journey. The Wrights' innovative methods, including wind tunnel testing, were instrumental in achieving this feat, establishing principles that would shape modern aeronautics. This exhibit not only highlights the Flyer as a mechanical marvel but also celebrates the Wright brothers' legacy in transforming the concept of human flight.|

[1]: Image sourced from [Smithsonian American Art Museum](http://n2t.net/ark:/65665/vk7e065d737-b5a1-4e2a-8d5a-45809fa25433).  
[2]: Image sourced from [Smithsonian National Museum of Natural History](http://n2t.net/ark:/65665/376132180-df00-4bb7-82ab-e0ad54e85b41).  
[3]: Image sourced from [Smithsonian National Museum of American History](https://n2t.net/ark:/65665/ng49ca746b5-2c91-704b-e053-15f76fa0b4fa).  
[4]: Image sourced from [Smithsonian National Air and Space Museum](http://n2t.net/ark:/65665/nv9aa91e7c2-85b2-4904-aff0-d990694b6f1d).  

## 4. File Structure 

#### 4.1. File Structure in the [Finetuned vs. OpenAI](./3.1_finetuned_vs_openai/) Run Folder

`./finetuned_vs_openai.ipynb`: A notebook for inferencing the test dataset using the `OpenAI GPT-4o` API  
`./my_utils_openai.py`: A library file containing utility functions specifically for running inference using the `OpenAI GPT-4o` API  
`./my_login.py`: A library file from previous fine-tuning experiments, reused for its login functions  
`./my_utils.py`: A library file from previous fine-tuning experiments, reused for its utility functions  
`./finetuned_inference_results/inference_results_before_finetuning.csv`: An inference result file from previous fine-tuning experiments, containing similarity scores of the `Base Model (No Fine-Tuning)`  
`./finetuned_inference_results/inference_results_after_lora_finetuning.csv`: An inference result file from previous fine-tuning experiments, containing similarity scores of the `LoRA Fine-Tuned Model`  
`./finetuned_inference_results/inference_results_after_full_finetuning.csv`: An inference result file from previous fine-tuning experiments, containing similarity scores of the `Full Fine-Tuned Model`  
`./results/inference_results/`: A folder storing `OpenAI GPT-4o` API's inference results and model quality comparison diagrams based on similarity scores  

## 5. OpenAI API and Hugging Face (HF) Credentials

In the [Finetuned vs. OpenAI](./3.1_finetuned_vs_openai/) experiment, we used the OpenAI GPT-4o API to generate responses to user queries based on exhibition images. Additionally, we leveraged models and datasets from the Hugging Face Hub to calculate similarity scores. To achieve this, we provided the `OpenAI API Key` and the `Hugging Face Access Token` within the notebook for this experiment.

Storing credentials for OpenAI and Hugging Face in environment variables is a common and recommended practice in machine learning workflows. However, in our experiments, we explicitly pass the credentials within the notebook. This approach simplifies the process, making it more accessible for beginners and easier to demonstrate.

When running your own experiments, make sure to enter your credentials in both the [Finetuned vs. OpenAI Notebook](./3.1_finetuned_vs_openai/finetuned_vs_openai.ipynb) and the reused [Login Library File](./3.1_finetuned_vs_openai/my_login.py).

## 6. API Call Cost

When running the experiment in the [Finetuned vs. OpenAI Notebook](./3.1_finetuned_vs_openai/finetuned_vs_openai.ipynb), OpenAI GPT-4o API calls used to generate answers for user queries based on exhibition images incur a small cost. The cost is approximately 22 cents, making it negligible.